%!TEX root =  main.tex


\chapter*{Chapter 11 The Exp3 Algorithm}
\label{sec:11}

\noindent\textbf{11.1} (\textsc{Sampling from a multinomial}) In order to implement Exp3, you need a way to sample from the exponential weights distribution. Many programming languages provide a standard way to do this. For example, in Python you can use the Numpy library and numpy.random.multinomial. In more basic languages, however, you only have access to a function rand() that returns a floating point number `uniformly' distributed in $[0, 1]$. Describe an algorithm that takes as input a probability vector $p \in \mathcal{P}_{k-1}$ and uses a single call to rand() to return $X \in [k]$ with $P (X = i) = p_i$.

\begin{proof}
Recall that the probability vector $p$ satisfies $\sum_{i=1}^k p_i = 1$. We can divide the interval $[0,1]$ into several slices. For example, the first is $[0,p_1)$, the second is $[p_1,p_1+p_2)$, ..., and the last is $[\sum_{i=1}^{k-1} p_i, 1)$. Every time we call rand(0,1) and get an output. The returned $X\in[k]$ is just the index of the slice in which the output falls. 
\end{proof}








\noindent\textbf{11.2} Let $\pi$ be a deterministic policy, and we define $x_{ti}=0$ if $A_t=i$ otherwise $x_{ti}=1$. The deterministic policy collects zero rewards all time,
\begin{equation}
    \max _{i \in[k]} \sum_{t=1}^{n} x_{t i} \geq \frac{1}{k} \sum_{t=1}^{n} \sum_{i=1}^{k} x_{t i}=\frac{n(k-1)}{k} \notag
\end{equation}

\noindent\textbf{11.5} Let $P$ be a probability vector with nonzero components and let $A\sim P$. Suppose $\hat{X}$ is a function such that for all $x\in \mathbb{R}^k$,
\begin{equation}
    \mathbb{E}\left[\hat{X}\left(A, x_{A}\right)\right]=\sum_{i=1}^{k} P_{i} \hat{X}\left(i, x_{i}\right)=x_{1}\notag
\end{equation}
Show that there exists an $a\in \mathbb{R}^k$ such that $<a,P>=0$ and for all $i$ and $z$ in their respective domains, $\hat{X}(i, z)=a_{i}+\frac{\mathbb{I}\{i=1\} z}{P_{1}}$
\begin{proof}
    Let $x, x'$ be arbitrary but agree on the first component $x_1=x_1'$. Let $f(x)=\sum_{i=1}^{k} P_{i} \hat{X}\left(i, x_{i}\right)$ Note that,
    \begin{equation}
        0=f(x)-f(x')=\sum_{i=j}^{k} P_{j} \hat{X}\left(j, x_{j}\right)\notag
    \end{equation}
    for all $j>1$. Since $x, x'$ are arbitrary, $\hat{X}(j, )=const$. Let $a_j$ equal to $\hat{X}(j, )$.
    \par Further, let $a_1=\hat{X}(1, 0)$ and then given any $x_1\in \mathbb{R}$, $\hat{X}\left(1, x_{1}\right)=a_{1}+x_{1} / P_{1}$.
    \par Finally, let $x$ be such that $x_1=0$. Then $0=f(x)=\sum_{i} P_{i} a_{i}$.
\end{proof}

\noindent\textbf{11.6}
(\textsc{Variance of Exp3}) In this exercise, you will show that 
if $\eta\in[n^{-p},1]$ for some $p\in(0,1)$,
then for sufficiently large $n$,
there exists a bandit on which Exp3 has a constant probability of suffering linear regret. We work with losses so that given a bandit $y \in[0, 1]^{n\times k}$, the learner samples $A_t$ from $P_t$ given by
\begin{align*}
    P_{t,i} = \frac{ \exp\bracket{-\eta\sum_{s=1}^{t-1}\hat{Y}_{si} } }{ \sum_{j=1}^k \exp\bracket{-\eta\sum_{s=1}^{t-1}\hat{Y}_{sj} } }
\end{align*}
where $\hat{Y}_{ti}=A_{ti}y_{ti}/P_{ti}$, let $\alpha \in [1/4,1/2]$ be a constant to be tuned subsequently and define a two-armed adversarial bandit in terms of its losses by $y_{t1}=0$ if $t\le n/2$ and $y_{t1}=1$ otherwise; $y_{t2}=\alpha$ if $t\le n/2$ and $y_{t2}=0$ otherwise. For simplicity you may assume that $n$ is even. 
\begin{enumerate}
    \item[(a)] 
    \item[(b)]
    \item[(c)]
    \item[(d)] Prove that $\PP{R_n\ge n/4} \ge (1-n\exp(-\eta n)/2)/65$.
    \item[(e)] The previous part shows that the regret is linear with constant probability for sufficiently large $n$. On the other hand, a dubious application of Markovâ€™s inequality and Theorem 11.1 shows that
    \begin{align*}
        \PP{\hat{R}_n \ge n/4}\le \frac{4\EE{\hat{R}_n}}{n} \le O(n^{-1/2})\,.
    \end{align*}
    Explain the apparent contradiction.
\end{enumerate}

\begin{proof}
\begin{enumerate}
    \item[(a)]
    \item[(b)]
    \item[(c)]
    \item[(d)]
    $\PP{\hat{R}_n\ge n/4}\ge \PP{A_t=1,\forall t>n/2}$ since when $A_t=1,\forall t>n/2$, we have $\hat{R}_n\ge n/2-\alpha\cdot n/2 \ge n/4$. In the following, we will try to lower bound $\PP{A_t=1,\forall t>n/2}$. 
    
    Based on the result of (c), we fist suppose $T_2(n/2)\ge s+1$. Then for any $t>n/2$, $\hat{L}_{t2}=\sum_{u=1}^{t-1}\hat{Y}_{u2}\ge 8\alpha n\ge 2n$. And $\hat{L}_{t1}=\sum_{u=1}^{t-1}\hat{Y}_{u1}=\sum_{u=n/2+1}^{t-1} 1/P_{u1}$. 
    Based on the event $T_2(n/2)\ge s+1$ and the fact that $P_{t1}\ge 1/2$, we can show that $\hat{L}_{t1}\le \hat{L}_{t2}$ for all $t$ by induction.
    Above all, 
    \begin{align*}
        P_{t2}\le \exp\bracket{ -\eta\sum_{s=1}^{t-1}(\hat{Y}_{s2}-\hat{Y}_{s1}) } \le \exp \bracket{ \eta\bracket{ \sum_{s=1}^{t-1}\hat{Y}_{s1}-2n} }\le \exp(-\eta n)\,.
    \end{align*}
    Further, based one (c), we have $\PP{\hat{R}_n\ge n/4}\ge \PP{A_t=1,\forall t>n/2} \ge 1/65\bracket{ 1-n/2\exp(-\eta n) }$.
    \item[(e)] The reason is that the result obtained by using Markov's inequality is not correct since $\hat{R}_n$ may be negative. 
    
\end{enumerate}
% \begin{itemize}
%     \item[(c)] Let $B_0, \dots, B_s$ be random variables following Geometric distribution, and
%     \begin{equation}
%         \mathbb{P}(B_n = k) = (1 - q_n(\alpha))^{k-1} q_n(\alpha), \quad \mathbb{E}[B_n] = \frac{1}{q_n(\alpha)}\notag
%     \end{equation}
%     Thus
%     \begin{equation}
%         \mathbb{P}\left(T_2\left(\frac{n}{2}\right) \geq s+1\right) = \mathbb{P}\left( \sum_{u=0}^s B_u \leq \frac{n}{2} \right) \geq \mathbb{P}\left( \sum_{u=0}^{s-1} B_u \leq \frac{n}{4} \right) \cdot \mathbb{P}(B_s \leq \frac{n}{4})\notag
%     \end{equation}
%     in which we have
%     \begin{enumerate}
%         \item 
%         \begin{equation}
%             \mathbb{E}\left[ \sum_{u=0}^{s-1} B_n\right] = \sum_{u=0}^{s-1} \frac{1}{q_n(\alpha)} \leq \frac{n}{8}\notag
%         \end{equation}
%         therefore by Markov's inequality,
%         \begin{equation}
%             \mathbb{P}\left( \sum_{u=0}^{s-1} B_u \leq \frac{n}{4} \right) = 1 - \mathbb{P}\left( \sum_{u=0}^{s-1} B_u > \frac{n}{4} \right) \geq \frac{1}{2};\notag
%         \end{equation}
%         \item By definition we have
%         \begin{equation}
%             \mathbb{P}\left[ B_s \leq \frac{n}{4} \right] =  1 - \left( 1 - \frac{1}{8n}\right)^{\frac{n}{4}} = 1 - \left( 1 - \frac{4}{32 n}\right)^{\frac{n}{4}} \geq 1 - \exp\left(-\frac{1}{32}\right)\notag
%         \end{equation}
%     \end{enumerate}
%     Therefore
%     \begin{equation}
%         \mathbb{P}\left(T_2\left(\frac{n}{2}\right) \geq s+1\right) \geq \frac{1}{2} \cdot \left( 1 - \exp\left(-\frac{1}{32}\right) \right) \geq \frac{1}{65}.\notag
%     \end{equation}
% \end{itemize}
\end{proof}

\noindent\textbf{11.7} First, note that if $G=-\log (-\log (U))$ then $\mathbb{P}(G \leq g)=e^{-\exp (-g)}$.
\begin{equation}
    \begin{aligned}
        \mathbb{P}\left(\log a_{i}+G_{i} \geq \max _{j \in[k]} \log a_{j}+G_{j}\right) &=\mathbb{E}\left[\prod_{j \neq i} \mathbb{P}\left(\log a_{j}+G_{j} \leq \log a_{i}+G_{i} \mid G_{i}\right)\right] \notag\\
        &=\mathbb{E}\left[\prod_{j \neq i} \exp \left(-\frac{a_{j}}{a_{i}} \exp \left(-G_{i}\right)\right)\right] \notag\\
        &=\mathbb{E}\left[U_{i}^{\sum_{j \neq i} \frac{a_{j}}{a_{i}}}\right] \notag\\
        &=\frac{1}{1+\sum_{j \neq i} \frac{a_{j}}{a_{i}}} \notag\\
        &=\frac{a_{i}}{\sum_{j=1}^{k} a_{j}}\notag
        \end{aligned}
\end{equation}

\noindent\textbf{11.8} (\textsc{Exp3 as follow-the-perturbed-leader}) Let $(Z_{ti})_{ti}$ be a collection of independent and identically distributed random variables. The follow-the-perturbed-leader (FTPL) algorithm chooses
\begin{align*}
A_{t}=\argmax_{i \in[k]}\bracket{Z_{ti}-\eta \sum_{s=1}^{t-1} \hat{Y}_{s i}}\,.
\end{align*}
Show that if $Z_{ti}$ is a standard Gumbel, then follow-the-perturbed-leader is the same as Exp3. 
\begin{proof}
% Let $\hat{X}_{ti}=1-\hat{Y}_{ti}$. 
Recall in Exp3, 
\begin{align*}
    \PP{A_t=i} = \frac{\exp\bracket{\eta \sum_{s=1}^{t-1} \hat{X}_{si} }}{\sum_{j=1}^k \exp\bracket{\eta \sum_{s=1}^{t-1} \hat{X}_{sj} }} \,, \text{ where } \hat{X}_{ti} = 1-\frac{ \bOne{A_t=i}(1-X_t) }{\PP{A_t=i} } = 1-Y_{ti}\,. 
 \end{align*}
 And in FTPL, 
 \begin{align*}
\PP{A_t=i} &= \PP{ i =\argmax_{j\in[k]} Z_{tj}-\eta \sum_{s=1}^{t-1} \hat{Y}_{sj}} \\
&= \PP{ i = \argmax_{j\in[k]}Z_{tj}-\eta \sum_{s=1}^{t-1} (1-\hat{X}_{sj})  } \\
&= \PP{ i = \argmax_{j\in[k]}Z_{tj}- \eta(t-1)+ \eta \sum_{s=1}^{t-1} \hat{X}_{sj}  } \\
&= \PP{ i = \argmax_{j\in[k]}Z_{tj}+ \eta \sum_{s=1}^{t-1} \hat{X}_{sj}  } \\
&= \PP{ i = \argmax_{j\in[k]}Z_{tj}+ \log a_j  }  \\
&= \frac{a_i}{\sum_{j=1}^k a_j} = \frac{\exp\bracket{\eta \sum_{s=1}^{t-1} \hat{X}_{si} }}{\sum_{j=1}^K \exp\bracket{\eta \sum_{s=1}^{t-1} \hat{X}_{sj} }} \,,
 \end{align*}
 where we set $a_i = \exp\bracket{\eta \sum_{s=1}^{t-1}\hat{X}_{si}}$ and apply the result of 11.7. 

 Above all, we have shown that the policy of FTPL is equivalent to that of Exp3. 


\end{proof}

